This repository contains some of my learning notes related to Machine Learning and Data Science.
  
### All notes in descending order (from new to old):
- Data Leakage
- Clustering Metrics
- NLP Metrics
- Computer Vision Metrics
- MSE, RMSE, MAE, R-squared (Regression Metrics)
- AdaBoost
- K-Nearest Neighbors Algorithm
- Hierarchical Clustering
- t-SNE
- Multidimensional Scaling
- Recommender Systems
- Anomaly Detection
- Accuracy, Precision, Recall, F1-score (Classification Metrics)
- Improving ML Model: General Methods
- Analysis of Variance (AVONA)
- Introduction to Neural Networks and Deep Learning
- Multiple Linear Regression
- Hypothesis Testing in Machine Learning
- Introduction to Object Recognition
- Kernel Density Estimation (KDE)
- Regularization in Practice
- Feature Engineering: Scaling, Categorical and Text Features
- Cross-Validation, Grid Search and Pipelines
- Logistic Regression
- Sensitivity, Specificity, ROC and AUC (Classification Metrics)
- Support Vector Machines
- Manifold Learning
- Gaussian Mixture Models
- Principal Component Analysis
- Naive Bayes
- Model Validation, Metrics and Hyperparameters
- Dimensionality Reduction
- K-means Clustering Algorithm
- Clustering in Machine Learning
- Classification in Machine Learning
- Training/Test Data, Models, Types of ML 
- Decision Trees, Bagging, Random Forests
- Keras
- Introduction to TensorFlow
- Introduction to OpenCV
- Scikit-Learn: An Introduction with Penguins!
- SciPy
- Likelihood Function
- Quantile, QQ-plots
- Coefficient of Determination (R-squared)
- Pearson Correlation Coefficient
- Bernoulli Distribution
- Standard Error
- Power Analysis
- How to Test a Hypothesis
- Skewness and Kurtosis
- Mode, Median, Variational Series
- Gradient Boosting with XGBoost
- Statistical Distribution and Sampling
- Stochastic, Batch and Mini-Batch Gradient Descent Algorithms
- P-value
- Poisson Distribution
- Exponential Distribution
- Fisher-Snedecor Distribution & F-Test
- Chi-Squared Distribution
- Student's T-Distribution & T-Test
- Binomial Distribution
- Population/Sample Parameters (Mean, Variance, SD)
- Logistic Regression
- Linear Regression
- Null & Alternative Hypothesis, Type I/II Errors
- Confidence Interval
- Discrete Random Variable
- Normal Distribution
- Probability Distribution and Cumulative Function
- Covariance
- Bootstrapping
- The Central Limit Theorem
- Variance and Standart Deviation
- Continuous Random Variable
- Operations with Probability, Types and Properties of Probability
- Conditional Probability, Bayes' Theorem
- Regularization: Ridge & Lasso Regression
- Overfitting, Underfitting and Bias-Variance Tradeoff
- Gradient Descent
- Probability Theory: Random Variable, Expectation, the Law of Large Numbers
- Matplotlib
- Pandas
- [NumPy: All in One](https://github.com/lenferdetroud/learning-notes/blob/main/Misc/numpy_all_in_one.ipynb)
